



https://github.com/AkiraXD0712/Hadoop_Spark_Kafka_Installation_Windows?tab=readme-ov-file



# Hadoop

https://dlcdn.apache.org/hadoop/common/

下载所有归档版本

https://archive.apache.org/dist/hadoop/common/





Tutorial for installing Hadoop 2.8.4, Spark 2.3, Pyspark and Kafka on Windows 10

Reference:

1. https://github.com/MuhammadBilalYar/Hadoop-On-Window/wiki/Step-by-step-Hadoop-2.8.0-installation-on-Window-10
2. http://blog.51cto.com/balich/2058194
3. https://stackoverflow.com/questions/25481325/how-to-set-up-spark-on-windows?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
4. https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f
5. https://j5technology.net/zookeeper-install
6. https://blog.csdn.net/u012050154/article/details/76270655
7. https://www.jianshu.com/p/b631c3899558
8. https://github.com/ruslanmv/How-to-install-Hadoop-on-Windows





## Download



https://archive.apache.org/dist/hadoop/common/



## Hadoop 2.x

2.8.2



安装JDK8







### Install Hadoop native IO binary

Hadoop on Linux includes optional Native IO support. However Native IO is mandatory on Windows and without it you will not be able to get your installation working. The Windows native IO libraries are not included as part of Apache Hadoop release. Thus we need to build and install it.

infoThe following repository already pre-built Hadoop Windows native libraries:



https://github.com/ruslanmv/How-to-install-Hadoop-on-Windows/tree/master/winutils/hadoop-3.3.0-YARN-8246/bin



warning These libraries are not signed and there is no guarantee that it is 100% safe. We use it purely for test&learn purpose.

Download all the files in the following location and save them to the bin folder under Hadoop folder.

You can use Git by typing in your terminal

```shell
git clone https://github.com/ruslanmv/How-to-install-Hadoop-on-Windows.git
```

and then copy

```
cd How-to-install-Hadoop-on-Windows\winutils\hadoop-3.3.0-YARN-8246\bin
copy *.*  C:\Hadoop\hadoop-3.3.0\bin
```











### 配置环境变量



**JAVA_HOME**

**HADOOP_HOME**

**PATH**：添加2个

```
%JAVA_HOME%/bin
%HADOOP_HOME%/bin
```





验证安装：hadoop -version











### 配置Hadoop

Hadoop 配置，其中涉及Hadoop核心配置、YARN、MapReduce、HDFS 配置。



%HADOOP_HOME%\etc\hadoop\core-site.xml

```xml
<configuration>
   <property>
     <name>fs.default.name</name>
     <value>hdfs://0.0.0.0:19000</value>
   </property>
</configuration>
```

创建目录

```
mkdir %HADOOP_HOME%\data\datanode
mkdir %HADOOP_HOME%\data\namenode
```

编辑%HADOOP_HOME%\etc\hadoop\hdfs-site.xml

```xml
<configuration>
   <property>
     <name>dfs.replication</name>
     <value>1</value>
   </property>
   <property>
     <name>dfs.namenode.name.dir</name>
     <value>/hadoop/hadoop-3.3.0/data/namenode</value>
   </property>
   <property>
     <!-- 这里使用的是绝对路径 -->
     <name>dfs.datanode.data.dir</name>
     <value>/hadoop/hadoop-3.3.0/data/datanode</value>  
   </property>
</configuration>
```



配置MapReduce

%HADOOP_HOME%\etc\hadoop\mapred-site.xml

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property> 
        <name>mapreduce.application.classpath</name>
        <value>%HADOOP_HOME%/share/hadoop/mapreduce/*,%HADOOP_HOME%/share/hadoop/mapreduce/lib/*,%HADOOP_HOME%/share/hadoop/common/*,%HADOOP_HOME%/share/hadoop/common/lib/*,%HADOOP_HOME%/share/hadoop/yarn/*,%HADOOP_HOME%/share/hadoop/yarn/lib/*,%HADOOP_HOME%/share/hadoop/hdfs/*,%HADOOP_HOME%/share/hadoop/hdfs/lib/*</value>
    </property>
</configuration>
```

%HADOOP_HOME%\etc\hadoop\yarn-site.xml

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>
```



### 初始化HDFS



```bash
hdfs namenode -format
```





```

%HADOOP_HOME%\sbin\start-dfs.cmd
```



Verify HDFS web portal UI through this link: http://localhost:9870/dfshealth.html#tab-overview.





```
%HADOOP_HOME%\sbin\start-yarn.cmd
```



http://localhost:8088/







## Hadoop 3.x

hadoop 3.1.3

https://archive.apache.org/dist/hadoop/common/hadoop-3.1.3/



## 常用端口号和配置文件

Hadoop 3.X
HDFS NameNode 内部通信端口：8020/9000/9820
HDFS NameNode HTTP UI：9870
HDFS DataNode HTTP UI：9864
Yarn 查看任务执行端口：8088
历史服务器通信端口：19888

Hadoop 2.X
HDFS NameNode 内部通信端口：8020/9000
HDFS NameNode HTTP UI：50070
HDFS DataNode HTTP UI：50075
Yarn 查看任务执行端口：8088
历史服务器通信端口：19888

|                           | Hadoop2.x | Hadoop3.x      |
| ------------------------- | --------- | -------------- |
| HDFS NameNode内部通信端口 | 8020/9000 | 8002/9000/9820 |
| HDFS NameNode Http UI     | 50070     | 9870           |
| HDFS DataNode Http UI     | 50075     | 9864           |
| MapReduce查看执行任务端口 | 8088      | 8088           |
| 历史服务器通信端口        | 19888     | 19888          |

s

Hadoop 3.X
core-site.xml
hdfs-site.xml
yarn-site.xml
mapred-site.xml
workers

Hadoop 2.X
core-site.xml
hdfs-site.xml
yarn-site.xml
mapred-site.xml
slaves

# Spark

https://spark.apache.org/downloads.html



历史版本下载

https://archive.apache.org/dist/spark/



https://archive.apache.org/dist/spark/spark-2.3.0/





https://github.com/josonle/Spark-The-Definitive-Guide-Learning





































